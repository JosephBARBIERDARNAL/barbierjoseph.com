{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"Hi! I'm Joseph <p>I recently founded yellow sunflower, an organization dedicated to creating open-source tools for data scientists and offering data consulting services.</p> ConsultingOpen sourceOtherBefore <p>Most of my consulting work focuses on making data workflows simpler, more reproducible, and visually clean, from analysis to reports.</p> <p>My core tools are Python/R for data work, Typst to create high-quality PDFs, and HTML/CSS/JS for web reports. I primarily work with clients in France (where I live!) and the United States. Feel free to send a message if you're interested!</p> <p>Most of my open-source work focuses on data visualization. I've developed and maintain multiple Python packages and made tons of contributions to the Python Graph Gallery and the R Graph Gallery.</p> <p>Sometimes I try to contribute to other projects too!</p> <p>I do some other things, such as YouTube videos, TidyTuesday challenges, and talks.</p> <p>Before working for my own company, I did internships at CIERI (research center), Wanteeed (e-commerce platform), and Dataviz Universe (Yan Holtz's company).</p> <p>I also hold a bachelor's degree in economics and a master's degree in applied mathematics and statistics, both from the University of Bordeaux.</p> <p></p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/","title":"ChatGPT's metric is not truthfulness","text":"Estimated read time: 10 min"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#tldr","title":"TLDR","text":"<p>Language models such as ChatGPT, for a given prompt, try to predict which word is most likely. Once they have done so, they repeat until the most likely word is the end of the sentence. The associated probabilities are defined using the training data in the model. Based on this, we can easily see that these models do not try to tell true things or give the best possible outcome (relative to what we would want), but only the most likely outcome. Furthermore, because of the way they are constructed, large language models have various unresolved interpretability and safety issues. Reinforcement learning with human feedback does not seem to be a very scalable way to make models safe, although OpenAI seems to think it might work.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#foreword-how-an-llm-works","title":"Foreword: how an LLM works?","text":"<p>If you are already familiar with the following concepts, you can skip this section because there will be nothing more: probability distribution, statistical model, machine learning, word embedding and fine tuning. It doesn't really matter if you don't understand everything. It is very complex and not necessary to understand the core of this article.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#probability-distribution","title":"Probability distribution","text":"<p>A probability distribution is a way of describing the chances or probabilities of different things happening in a given situation. It is like a map that shows all the possible outcomes and the likelihood of them occurring. By looking at this map, we can determine what the most likely outcome is, what the range of possible outcomes is, and what the probability of the different outcomes is. A language model wants to predict what is the most likely word that will occur (not totally accurate, but that doesn't matter here) after a sequence of words. For example, what is the most likely word after the sentence \"The day is off to a bad start, my car crashed this \u2026\"? A language model might suggest something like \"morning\" with 60%, \"afternoon\" with 25%, \"evening\" with 10%, and other words for the last 5%. This is a probability distribution of what is the most likely word for that sentence.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#statistical-model","title":"Statistical model","text":"<p>A statistical model is a simplified representation of a real-world situation that uses mathematics to help us understand how different factors relate to each other. It allows us to make predictions about what might happen in the future based on what we have observed in the past. Think of it as a map that helps us navigate and understand a complex landscape. Just as a map can show us the location of different cities or landmarks, a statistical model can help us understand how different variables such as age, gender, income, or education may relate to each other. Although statistical models involve mathematics, you don't need to know it to understand the basic concepts behind it. The parameters of language models are determined so that they predict the next most likely word at a given state. To do this, we show them many examples (mostly texts from the Internet) and they keep the patterns present in these texts. Example: most conversations containing \"How are you?\" are followed by \"Fine, and you?\" (or something similar). It is not a universal property that we respond with \"Fine, and you?\", but it is a pattern in the sense that it is something that happens most of the time. ChatGPT is a complex language model that \"understands\" many (most?) of the language patterns that we (humans) use when we communicate via text.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#machine-learning","title":"Machine learning","text":"<p>Machine learning is a method of teaching computers to perform tasks without being explicitly programmed to do so. Instead of giving the computer a set of instructions, you give it a large amount of data and let it \"learn\" patterns and relationships in the data. The computer uses these patterns to make predictions or decisions on new data that it has not seen before. Machine learning is used in a wide range of applications, from image and speech recognition to recommendation systems and self-driving cars.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#word-embedding","title":"Word embedding","text":"<p>Since computers cannot interpret text itself, we had to create an architecture that allows us to go from text to mathematics, and from mathematics to text (to put it simply). Word embedding is a technique used in natural language processing to represent words as numerical vectors (if you are not at all familiar with vectors, think of them as mathematical objects, like numbers, functions, addition\u2026) in a high-dimensional space. This allows machines to analyze and understand the meaning of words based on their relationships to other words in the same space. Essentially, word embedding helps computers interpret language in a way that approximates the way humans do. The beauty of vectors is that you can do mathematical operations on them, unlike text. For example, a famous example of embedding is that when we remove the vector equivalent of \"man\" from the vector equivalent of \"king\" and add the vector equivalent of \"woman\", we get the vector equivalent of \"queen\", which makes a lot of sense to us! More intuitively: king - man + woman = queen.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#fine-tuning","title":"Fine tuning","text":"<p>Fine-tuning is a common approach used in natural language processing (NLP) to improve the performance of pre-trained models on specific tasks such as text classification, language translation or question answering. First, ChatGPT was pre-trained on many different texts from the Internet without any specialization (i.e., it does not specialize in translation, code completion, text classification or anything else). Then it was fine tuned using reinforcement learning with human feedback (we will see later what this is about). This means that we ask humans to chat with it, and every time the response is considered harmful, sexist or racist, people send it negative feedback to make it learn the pattern it should avoid, and vice versa. By doing this many times, the model tends not to be harmful.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#on-a-broader-level","title":"On a broader level","text":"<p>ChatGPT has been trained on a lot of text from the internet, and the internet contains a lot of stuff: from Javascript code to German literature to Minecraft sub reddits. From this, it learns text patterns and draws generalizations from them. When we give it a prompt, it puts a probability distribution on the most likely word that should appear. If we use our last example, the model predicts \"The day is off to a bad start, my car crashed this morning\" since \"morning\" is the most likely word. It will then repeat the same thing, but the prompt will be \"The day is off to a bad start, my car crashed this morning\" and predict the next word, over and over, until the most likely word is the end of the sequence. The most important thing to keep in mind about how chatGPT works is that it doesn't use the Internet or any database, but only tries to predict the most likely word based on what it has seen. And while there may be a correlation between them, what is true and what is most likely are not the same thing. Now that you know the basics of how LLMs like ChatGPT work, let's look at the problems in more detail.</p> <p>Example of how LLM like ChatGPT responds to the prompt: \"Hello sir, any mail for\":</p> <ul> <li>chatGPT calculating a probability distribution of what the next word in this state might be \"Hello sir, any mail for me\"</li> <li>chatGPT calculating a probability distribution of what the next word in this state might be \"Hello sir, any mail for me today?\"</li> <li>chatGPT calculating a probability distribution of what the next word in this state might be \"Hello sir, any mail for me today? No\"</li> <li>chatGPT calculating a probability distribution of what the next word in this state might be \"Hello sir, any mail for me today? No sorry\"</li> </ul> <p>This will happen until the most likely word is nothing. Actually, chatGPT doesn't really try to predict words but rather tokens, but you can consider it more or less the same thing.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#reinforcement-learning-with-human-feedback","title":"Reinforcement learning with human feedback","text":"<p>Reinforcement learning (RL) is a type of machine learning in which an agent learns to perform a task through trial and error. The agent interacts with an environment, receives feedback in the form of rewards or penalties, and uses this feedback to adjust its behavior over time. The agent's goal is to maximize its long-term reward by learning which actions to take in which situations.</p> <p>One approach to using human feedback in RL is to have humans provide feedback during the learning process. In this case, humans can guide the agent on what actions to take in certain situations, or provide feedback on the agent's decisions in real time. This type of feedback can be particularly useful in situations where the agent is learning a complex task and may need additional guidance to achieve good performance.</p> <p>In the case of LLMs, OpenAI (the creators of ChatGPT) used reinforcement learning with human feedback (RLHF) by employing dozens of people (called AI trainers) and asking them to rank model outputs for a given text input.</p> <p>Who did it? What were the criteria? Since the goal of RLHF is to make LLMs less harmful, we need to define them. If we want to be rigorous, we should make explicit the method used since this is an important feature of ChatGPT. But OpenAI chooses not to give any information about this: what was considered harmful? Were instructions given to the AI trainers before or during the training phase? The heart of the problem is that this method will never be 100% safe since it is approximate: the model will tend to be non-harmful (according to a subjective, undefined definition). With enough roleplay (example here), you can make ChatGPT say harmful things easily. Rather than working on the real security issues like developing a better understanding of LLM decisions (interpretability issues), OpenAI unfortunately chose the easy way out. Moreover, according to Time magazine, there are other ethical problems (not discussed here).</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#goodharts-law","title":"Goodhart's law","text":"<p>ChatGPT's metric is not truthfulness As you should understand by now, ChatGPT is not a search engine. Rather, it is an agent that tries to suggest as many answers as possible to our prompts. However, unlike a human agent, its reasoning is very specific: it predicts what the most likely word will be until the end of the sequence. And what is most plausible in a discussion and the truth are not the same thing. The metric of ChatGPT is not truthfulness. In fact, we are not able to create a similar ChatGPT whose goal will be to say what is true since it is extremely complex to formally ask an LLM to be as true as possible. One could argue that we can simply train the LLM only on texts that are true. But how do we objectively distinguish a text that is true from one that is not? What is true (not so easy to answer\u2026)? And even if we were able to solve these questions, there is no reason to think that this guarantees that the model will only say true things.</p> <p>What if ChatGPT's metric was truthfulness? Goodhart's Law (named after the economist Charles Goodhart) is a concept that states that \"When a measure becomes a goal, it ceases to be a good measure\". In other words, when a specific measure or indicator is used to assess or induce a particular behavior, people may change their behavior to achieve that measure, even though it may not reflect the true desired outcome. This can lead to unintended consequences and distortions in the system being measured. This means that even if we create a model that optimizes for veracity, there will still be no reason for the model to say the wrong things. One name for this problem is the specification gaming: we are not able to specify clearly what we want. You can find examples of this problem in this article from Deepmind.</p> <p>More generally, the measurement problem is not specific to the field of AI but to statistics as a whole. I will soon write an article on a similar topic. Check out this excellent article about the same subject (also available as a podcast) if you are interested.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#various-information","title":"Various information","text":"<p>ChatGPT is overconfident, regardless of his \"knowledge\". It regularly says false things with the same confidence as basic facts. It is problematic when users with no knowledge of how LLMs work (probably the majority of its current users) use it.</p> <p>Examples of LLMs that are harmful, behave strangely or are used maliciously:</p> <ul> <li>Chat is blatantly, aggressively misaligned</li> <li>SolidGoldMagikarp (plus, prompt generation)</li> <li>ChatGPT's Dark Side: An Endless Supply of Polymorphic Malware</li> </ul>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#utility-and-upgrade-direction","title":"Utility and upgrade direction","text":"<p>ChatGPT is extremely powerful and very impressive. It is ultra versatile, can handle complex concepts, and can be very useful (assuming you don't use it blindly) for specific tasks like summarizing, solving coding problems, proposing an outline for an essay\u2026 It's probably not a problem in itself to use it on a daily basis: it can be an incredible time-saving tool. But it is not the right tool when you want to learn history, check facts, and generally find accurate information. For example, a journalist has to be careful when using it, especially since he can't give any references (and if he does, you might be surprised by the accuracy of them). fake reference</p> <p>chatGPT which gives a reference that has the same title conventions as other research papers, but does not exist (I did not use prompt engineering).</p> <p>LLMs are complex models that require people working on their interpretability. If OpenAI really wanted to create safe AI (\"We will attempt to directly build safe and beneficial AGI\" OpenAI), they would probably choose to focus more on LLM interpretability rather than using RLHF to prevent non-safety.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#closing-remarks","title":"Closing remarks","text":"<p>The real problem with all of these issues is that they won't be solved with the next default LLM. A more powerful model might just focus on these issues.</p> <p>I really hope that the problems with ChatGPT, and LLMs more generally, are now a bit clearer. It's important that we understand the tools we decide to use, especially when they're used by millions of people around the world and will probably tend to grow rapidly.</p>"},{"location":"blog/chatGPT-metric-is-not-truthfulness/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"},{"location":"blog/does-chatGPT-regret-what-it-says/","title":"Does chatGPT regret what it says?","text":"Estimated read time: 4 min"},{"location":"blog/does-chatGPT-regret-what-it-says/#tldr","title":"TLDR","text":"<p>The way chatGPT was built (i.e: the transformer architecture) suggests that when it's starting to answer a prompt, it's unlikely to suddenly change direction along the way. This is a similar phenomena when someone asks you your opinion about X, you start answering something, but during your explanation you feel that what you say is partially wrong or it would have been better to say something else. However, you also feel that it would be a bit ridiculous to admit that what you just said wasn't the best answer you could give. The (partial) solution of this problem is to abuse of the temperature parameter, which defines the randomness in chatGPT's answers. This implies that, for a given prompt, it will answer different things and give us a better panel of the possible answers.</p>"},{"location":"blog/does-chatGPT-regret-what-it-says/#foreword-how-llms-work","title":"Foreword: how LLMs work?","text":"<p>For a more detailed explanation about language models, check this article.</p> <p>When using chatGPT on the official OpenAI website, you can see that its answers are coming word by word (or token by token to be specific). This isn't only a UI/UX decision by OpenAI but also the way chatGPT works. When it receives a prompt, chatGPT uses a probability distribution to determine the most likely word that should follow. For example, what's the most likely word, based on your experience: \"I'm so hungry, I really [word]\"? Personally, I'd say \"need\" or \"want\". Once it's done, the process continues again and again. This process is repeated iteratively, using the previous sequence as a new prompt, predicting the next word and continuing until the most likely word marks the end of the sequence.</p> <p>It's essential to note that chatGPT works without access to the Internet or an external database. It relies solely on its past exposure to data to predict the most appropriate word at a given moment in the text.</p>"},{"location":"blog/does-chatGPT-regret-what-it-says/#an-example-with-programming","title":"An example with programming","text":"<p>Don't worry, there are no programming prerequisites to understand this section.</p> <p>You now understand the basic functioning of chatGPT. This way of \"reasoning\" implies that chatGPT may \"lock\" itself in a direction that is not optimal. In order to make it intuitive, we will talk about programming.</p> <p>When coding, you regularly need to import packages. Packages are a group of functions, coded by other developers, that do stuff. The point behind using packages is that it makes you gain lots of time since you can use super useful functions without even knowing how they work. For example, if you want to create some charts with the Python programming language, you regularly use the Matplotlib package since it has a lot of tools, very easy to use, that create very customizable charts. You can also use the Seaborn package, similar and related to Matplotlib, but with some different features. One last detail about packages is that generally a code looks like this: you first \"call\" the package, and then you write your code.</p> <p>To this, if we add the way chatGPT works, we can reveal something interesting. When chatGPT is writing code, it will first write the import package1 etc, and then write the code. And since it uses past words to predict the next word, it means that it will only (theoretically, but that's usually true) use functions from the imported packages.</p> <p>This also means when it has finished importing the packages (let's say it just imported the matplotlib package), it will not use the seaborn package, even though it would have been a good idea for this issue. You can think of it intuitively if you ask someone the best scientific argument that proves global warming, and the person starts saying that it's pretty hot outside today. It was one of the possible answers, but probably not the best one. Once it started, for most humans, it's hard to say \"I was wrong, this argument is not a good one\". And chatGPT is even worse than humans because the way it works reinforces the fact that once you've started making mistakes, you're stuck with them.</p>"},{"location":"blog/does-chatGPT-regret-what-it-says/#the-solution-increase-the-heat","title":"The solution: increase the heat","text":"<p>It would be super cool if it was possible to have let's say 3 or 4 chatGPT, trained (or finetuned) on different data, to compare their answers. So far it's not possible (as far as I know), but we can use a \"trick\" or a \"masked\" feature from chatGPT: the temperature. The temperature of a language model is a setting that affects the randomness of its responses. Have you ever seen that chatGPT give you slightly different answers even when you give it the exact same prompt?</p> <p>When using chatGPT on the official website we can't change this parameter: we don't even know its current value. But when using it with the OpenAI API (this just means using it in another service like google doc, some coding program or anything else), you can choose this parameter value. It ranges from 0 (answers are deterministic, no randomness and the model tends to always answer the same thing to the same prompt) to 2 (highly random model, answers may be very significantly different for the same prompt).</p> <p>The technique here is to use this parameter to see different responses to the same prompt, so as to be able to compare them. When ChatGPT generates text, it does so by predicting the next word in the sequence based on the previous words. The next word is predicted using a probability distribution over the entire vocabulary of the model. Each word in the vocabulary has an associated probability that indicates how likely it is to be the next word in the sequence.</p> <p>Adjusting the temperature will affect the importance of each word. If the temperature is high, the probabilities will be more uniform, meaning that the model will be more exploratory and make less certain choices. This can lead to more creative and diverse responses, but it could also produce less consistent or riskier results.</p>"},{"location":"blog/does-chatGPT-regret-what-it-says/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"},{"location":"blog/dont-try-to-reverse-engineer-the-data/","title":"Don't try to reverse engineer the data","text":"Estimated read time: 3 min"},{"location":"blog/dont-try-to-reverse-engineer-the-data/#tldr","title":"TLDR","text":"<p>It does not feel uncommon to me to see people that want to quickly make the first analysis of a dataset by looking at the data and trying to understand it. I think this is a mistake, because except if you are working with a very simple dataset, you'll spend too much time trying to infer what is the data about and its structure. Instead, I would recommend to start by looking at the documentation of the dataset, and more generally try to find info about how data was collected, what it represents, and how it is structured.</p>"},{"location":"blog/dont-try-to-reverse-engineer-the-data/#reverse-engineering","title":"Reverse Engineering","text":"<p>Reverse engineering is the process of discovering the technological principles of a device, object, or system through analysis of its structure, function, and operation. It often involves taking something apart and analyzing its workings in detail to be used in maintenance, or to try to create a new device or program that does the same thing without copying the original.</p> <p>In this post, the term \"reverse engineering\" is more used as a metaphor rather than in its strict sense. I'm talking about the process of trying to understand a dataset by looking at its content and structure, without any prior knowledge about it.</p>"},{"location":"blog/dont-try-to-reverse-engineer-the-data/#data-format","title":"Data format","text":"<p>In my opinion, the key is to know the format of the data. Before diving into any, even very basic, analysis, we should always be able to explicitly say what one row of the dataset represents, and what each column is about.</p> <p>For example, let's say we want to create a machine learning model that predicts if a doctor is a good doctor or not. Our dataset contains info on medical visits, the doctor that performed it, the patient, the date, the diagnosis, the outcome after X days, etc. We should be able to say that one row of the dataset represents one medical visit.</p> <p>One mistake would be to model the outcome on this dataset, even tough we don't want to predict the outcome of a medical visit, but the quality of the doctor. In this case, we should have a dataset where one row represents one doctor. We also have to find a way of measuring the quality of a doctor, and this is not trivial.</p>"},{"location":"blog/dont-try-to-reverse-engineer-the-data/#real-life","title":"Real life","text":"<p>In the previous example, it may seem obvious, but it's because I've explicitly said what the dataset is about and what was the goal. If you want to actually obtain insights, you will usually take an underexplored dataset, and you will have to find out what it is about.</p> <p>If you go on Kaggle, you will see that some of the datasets are well documented (don't use the others!). I highly suggest you to spend time on the documentation before importing the data in order to ensure that you have the tools to understand it. One good point is that you can literally ask the author of the dataset where the data came from, how it was collected, etc. and this will save you a lot of time AND errors.</p> <p>It's actually very easy to directly open the dataset in your editor and start looking at the data, but you have to force yourself to ask \"What one row actually represents?\". If you are not able to answer this question, there is a high chance that your analysis won't make sense.</p>"},{"location":"blog/dont-try-to-reverse-engineer-the-data/#pre-requisites","title":"Pre-requisites","text":"<p>Here I define some pre-requisites that I think are necessary to be able to analyze a dataset. You should at least be able to answer these questions explicitly in a clear sentence:</p> <ul> <li>What one row represents?</li> <li>What each column is about?</li> <li>What is the goal of the analysis?</li> <li>Is the format of the data adapted to the goal?</li> </ul>"},{"location":"blog/dont-try-to-reverse-engineer-the-data/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"},{"location":"blog/fake-data-science-jobs/","title":"Fake data science jobs","text":"Estimated read time: 3 min"},{"location":"blog/fake-data-science-jobs/#tldr","title":"TLDR","text":"<p>Some so-called \"data science\" jobs you've come across might seem odd. These roles often focus on data labeling, a repetitive task that involves assigning \"labels\" to data. This process can take various forms, but in this case, it revolves around labeling, comparing, and ranking code based on its quality. It's crucial for training AI systems, such as large language models (LLMs), by providing high-quality labels to improve their coding abilities. Once companies hire these \"data scientists,\" they have them label and rank code or LLM outputs, then sell this labeled data to businesses training AI models.</p>"},{"location":"blog/fake-data-science-jobs/#weird-job-offers","title":"Weird Job Offers","text":"<p>If you work in a field related to data science/analysis, you might have encountered some peculiar job offers. These job titles usually contain the word \"data\" and mention the task of doing data analysis, but they are far from what we usually mean by data analysis (ETL, database, modeling, A/B testing, dashboards, etc.).</p> <p>Let's see what these job offers look like:</p> <p>Interesting things to note:</p> <ul> <li>Looking for multiple persons (use of plural)</li> <li>No idea of what the projects are about or the kind of clients</li> <li>Focus on being able to express one's reasoning and logic</li> <li>Mention of \"AI\" while the job doesn't seem related to AI on technical aspects</li> </ul>"},{"location":"blog/fake-data-science-jobs/#i-applied","title":"I Applied","text":"<p>Since I was very curious, I applied to the job offer to understand more about it. I then filled in the basic info they asked for. And then, for some reason, they really wanted me to work with them:</p> <p></p> <p>They kept saying in their messages that I only had a few days to do their tests, and otherwise I would be removed from the recruiting process. What's even more interesting is that they didn't know much about my skills, but they still sent lots of automatic messages, meaning I'm probably not the only one in this case.</p>"},{"location":"blog/fake-data-science-jobs/#other-job-offers","title":"Other Job Offers","text":"<p>Let's have a look at different job offers, but from other companies to highlight the nonsense.</p>         Here we have an offer that has a ridiculous pay rate, a very suspicious required experience, and a weird location requirement (probably working solo on data labeling tasks with zero meetings).  <p></p>          This other offer literally doesn't ask for any experience, nor any programming/data skills. When we look at the description, this has nothing to do with data analysis, and they have very weird requirements such as living in France for at least 5 years. Their benefits only focus on the \"flexibility\" of the job (once again: solo work on data annotation with no meetings).      <p></p>         On this other job offer from another company, we find a similar pattern with very specific requirements and no mention of data analysis whatsoever. Interestingly, they mention \"extra income\" for their remuneration, as if this was not even a real job but just a side thing to do."},{"location":"blog/fake-data-science-jobs/#the-actual-job","title":"The Actual Job","text":"<p>I found a platform where it was easy to access the tasks and tried a few exercises (I even made $0.54). And as I said before, the tasks are nothing close to data analysis. Here is the description of the project I worked on:</p>  \"In this task, you'll see a prompt that's related to coding, such as generating code, explaining code, debugging a code snippet, writing comments/documentation, etc. You'll also see two responses from different models that attempt to respond to the prompt. Your job is to look closely at each response and determine the following: How correct is the response? How well did the response follow the prompt's instructions? Were you able to run the code in the response to check its correctness? Based on the correctness of each response, which is better?\"  <p>The code they are talking about was related to data science, but was so vast it does not make any sense to look for \"data analysts\" to assess it. The first question was about using AutoML and Google Cloud, while the second question was about backend in Go.</p> <p>There is lots of text to read (assignment + compare 2 LLMs output on long tasks), with very specific questions such as:</p> <p>This might be only personal, but I find this kind of task very boring while requiring lots of focus. You lose all the fun parts about programming (aka solving a problem).</p>"},{"location":"blog/fake-data-science-jobs/#the-problem","title":"The Problem","text":"<p>One could argue that there is no problem with this kind of job. And in itself, it's true. It offers more job opportunities to more people. But the fact that they suggest that this is a real data science position can lead to some surprises.</p> <p>These jobs will not help you get a job as a data analyst, nor get related skills. You will not work on real projects, but rather work on some sort of \"meta data analysis\", which consists of labeling and ranking tasks related to data analysis.</p> <p>Another issue I see here is that they are not very explicit about what the job is about, and how it works. If you want to have a career in the data world, these jobs are probably the last ones you want to apply to.</p>"},{"location":"blog/fake-data-science-jobs/#will-this-make-ai-better","title":"Will This Make AI Better?","text":"<p>Probably not. As I mentioned earlier, the company's main goal is to sell the labeled data to other businesses. My opinion is that since these jobs are far from enjoyable, skilled developers are unlikely to be interested. Instead, the work will likely be done by people who, unfortunately, haven't been able to secure more desirable positions. Offering high pay could attract better talent, but the best rates I've found are around $50 per hour\u2014and even those are rare and require passing multiple tests.</p>"},{"location":"blog/fake-data-science-jobs/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"},{"location":"blog/how-not-to-do-a-data-science-project/","title":"How (not) to do a data science project","text":"Estimated read time: 5 min"},{"location":"blog/how-not-to-do-a-data-science-project/#why-this-post","title":"Why this post","text":"<p>In order for people to find value in your work in data science (and want to hire you!), you need to show them what you've worked on. In practice, this will mostly be school projects or side projects.</p> <p>But when someone starts working on their first data science projects, they inevitably fall into basic traps that make their project look boring/useless/ugly, even if the project is an amazing idea.</p> <p>Here, I want to share what I think would make a great data science project (not enterprise production-level, but mostly side projects).</p>"},{"location":"blog/how-not-to-do-a-data-science-project/#put-your-project-online","title":"Put your project online","text":"<p>Whatever your project is\u2014a machine learning model, an exploratory analysis, a chart, a package, or anything else\u2014it needs to be visible somewhere. And those places are:</p> <ul> <li>GitHub: A place where most developers in the world put their code. Knowing how to work with Git and GitHub is a huge bonus point. And I'm sure ChatGPT will help you get started super easily.</li> <li>A website: Instead of just uploading a Jupyter Notebook to a GitHub repo, make it a website! With tools like Quarto and GitHub Pages, it has never been easier to create a beautiful website from a data science analysis (and it's free).</li> </ul> <p>If you know how to use the basics of Git, GitHub, and Quarto, the hardest part is already done, and your work's quality just increased 10x.</p> <p>A friend of mine has a course dedicated to this objective!</p>"},{"location":"blog/how-not-to-do-a-data-science-project/#make-it-reproducible","title":"Make it reproducible","text":"<p>Data science suffers from not being very rigorous in terms of good software development practices. This isn't because of data science itself, but I think mostly because of how we tend to learn it. However, a good data scientist is actually a software developer.</p> <p>So how do you make a project reproducible? Here are a few things you need to do:</p> <ul> <li>Use a package manager. This ensures you know the exact versions of the packages you used (e.g., scikit-learn 1.6.3, etc.). In Python, I recommend uv. In R, I've only heard about renv.</li> <li>Don't use Jupyter Notebooks. This might be controversial, but there are so many better alternatives: just using a plain <code>.py</code> file, Quarto (mentioned earlier), Marimo, etc.</li> <li>Never write absolute paths in your code (e.g., <code>C:\\Users\\User\\Documents\\data.csv</code> or <code>/home/user/documents/data.csv</code>). Learn the difference between relative and absolute paths, and stop creating projects that only run on your computer.</li> </ul>"},{"location":"blog/how-not-to-do-a-data-science-project/#keep-only-what-matters","title":"Keep only what matters","text":"<p>Most people are not interested in seeing the first few rows of a dataset or a printout of how many rows/columns your dataset has.</p> <p>Approach your project like you're solving a problem: separate the internal workings of your program (e.g., printing the first few rows) from the final report, which should highlight the most important results. Data science is not useful in itself\u2014most people aren't interested in the technical aspects; they want to see actual value.</p>"},{"location":"blog/how-not-to-do-a-data-science-project/#tell-me-a-story","title":"Tell me a story","text":"<p>I want to know what's the point of this project without having to dig into it. Instead of presenting \"my car price prediction project,\" explain how being able to predict car prices is valuable for certain people. The reason can also simply be that you're interested in the topic\u2014but you still need to justify what you're doing.</p> <p>Mentioning other people's work on the subject is also interesting\u2014compare their methods/results with yours, etc.</p> <p>In general, give me reasons why I should be interested in your project. If the first thing I see in your project is \"First I import the packages,\" something is wrong.</p>"},{"location":"blog/how-not-to-do-a-data-science-project/#make-nice-charts","title":"Make nice charts","text":"<p>Visualization is the most visual thing in your project, so make it look nice. It doesn't have to be complicated\u2014it\u2019s about taking the time to make it look polished. If you're using Python, check out the Python Graph Gallery. In R, check out the R Graph Gallery.</p> <p>I've also created a course to help you create great charts with Matplotlib.</p>"},{"location":"blog/how-not-to-do-a-data-science-project/#going-further","title":"Going further","text":"<p>If you've followed all the previous steps, your project is already really good, and I want to take a look at it. But if you want to make your project even better, here are a few additional things that I think are really valuable:</p> <ul> <li>Write unit tests.</li> <li>Use a code formatter.</li> <li>Create a CI/CD pipeline.</li> </ul> <p>There are many other improvements you can make, but these are a great start! Congratulations\u2014you\u2019re now much more credible when presenting one of your projects to someone.</p>"},{"location":"blog/how-not-to-do-a-data-science-project/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"},{"location":"blog/its-not-even-correlation/","title":"It's not even correlation","text":"Estimated read time: 5 min"},{"location":"blog/its-not-even-correlation/#tldr","title":"TLDR","text":"<p>Our brains often jump to conclusions about causality without good reason, looking for patterns and links where there are none. In everyday life, we may mistakenly assume that there is a causal link based on a simple correlation. For example, when studying success, it's important to focus on differences rather than similarities, and not to rely on self-reported data, as individuals may not really understand the reasons for their own success. Chance plays a bigger role than we think, and understanding it can help avoid logical fallacies. For more on this subject, read \"Fooled by Randomness\".</p> <p>To understand the characteristics of a group, it is essential to take into account the characteristics of people outside the group. False data are used to show that studying a population group does not provide information about what defines it. It is necessary to compare populations and look for differences rather than similarities. People often overlook what they don't know, which underlines the importance of being aware of missing information.</p>"},{"location":"blog/its-not-even-correlation/#causality-everywhere-dumb-brain","title":"Causality everywhere, dumb brain","text":"<p>We tend to fall easily into the trap of inferring causality without valid reasons. To get those reasons, you need solid data. However, this article is not about the error that can be found in research or data analysis, but in our everyday lives.</p> <p>Indeed, human beings often tend to infer causal links, even if they are unfounded. Our brains often look for patterns and connections, and we sometimes mistakenly perceive cause and effect where there is none. While solid data and rigorous analysis are needed to establish cause-and-effect relationships in scientific research, in everyday life we don't always have access to such solid evidence. This can lead to various biases and logical fallacies when trying to determine causality.</p> <p>One example is the correlation-causation fallacy, where people assume that simply because two things are correlated, one must be the cause of the other. However, correlation alone does not imply causation. Other underlying factors or coincidences may be behind the observed relationship. However, what I want to talk about here is the fact that most of the time, what we observe is not even a correlation.</p>"},{"location":"blog/its-not-even-correlation/#focus-on-differences-not-similarities","title":"Focus on differences, not similarities","text":"<p>Suppose you want to know what makes people successful. There are two different ways of approaching this problem.</p> <ul> <li>looking for correlating factors: looking for things that successful people do/have/are and that others don't.</li> <li>looking for causal factors: looking for the determinants of success (not discussed in this article).</li> </ul> <p>We (and most people interested in this subject) decide to take the simplest option with correlated factors. Intuitively, we want to interview different successful people and ask them questions about their lifestyle, the reasons for their success and try to find commonalities. But this method poses a major problem: we have to look for differences, not similarities. The famous reasons that I have the impression people associate with success are: working hard, being fit/exercising regularly, being highly motivated, reading, meditating, etc. And it's plausible that, in the course of interviews, these elements come up in discussion. However, if most successful people play sports regularly, does that mean there's a correlation with being successful and those? Not at all.</p> <p>That's where the differences are important. It makes no sense to look for similarities since you have nothing to compare your sample to. For example, many unsuccessful people play sports regularly. We're probably looking for similarities because we have preconceptions about what makes people successful.</p> <p>What's more, during the interview, the interviewee confidently told you that he or she did sport and considered it an important part of his or her success. But unfortunately, there's no reason to think they know why they're considered successful. Would you ask a sick person the reason for their illness? It's bad practice to be the subject of your own study. That's why randomized controlled trials are conducted and placebos are used. In \"Fooled by Randomness: The Hidden Role of Chance in Life and in the Markets\", Nassim Taleb explains why we don't like chance as an explanation of a phenomenon, why it happens more often than we think, and how we tend to rationalize it. If you want to go further, this is the book for you.</p>"},{"location":"blog/its-not-even-correlation/#make-sure-you-are-measuring-something","title":"Make sure you are measuring something","text":"<p>When you want to know the characteristics of a group of people, you have to make sure that you always have the characteristics of people who are not part of that group. Otherwise, you probably won't be measuring anything at all. To make this more intuitive, let's take some examples. I've arbitrarily taken two characteristics: time spent reading and time spent doing sport.</p> <p>In our minds, it might look like this: the more you read and do sport, the more likely you are to succeed. If this data were true, the final conclusion would be logical.</p> <p>But this is only possible because we are not only looking at the characteristics of one group, but of everyone. If we only look at the characteristics of a group, we can't say anything about what defines it.</p> <p>On Angela Duckworth's Wikipedia page (a professor who wrote a bestseller entitled \"Grit: The Power of Passion and Perseverance\"), we read that \"Duckworth found that courage was a common factor in the high-achievers she studied\". With the last sentence, we have no reason to draw any conclusions about \"high achievers\", contrary to what it suggests*. It illustrates that \"studying\" a population group gives you no information about what makes them part of that group.</p> <p>*Note: I'm not familiar with Duckworth's work (I've only read her book) and she's probably not the author of this sentence, but this example illustrates my point well.</p> <p>Moreover, by looking only at successful people, we can easily forget that there is actually no relationship between the two characteristics. And the only way to know that, is to compare populations and seek for differences instead of similarities.</p> <p>Next time someone tells you \"most people doing X is Y\", check if this can be simply explained by \"most people are doing X\".</p>"},{"location":"blog/its-not-even-correlation/#closing-remarks","title":"Closing remarks","text":"<p>Conceptually, depending on what you know at the time, you can give \"epistemological weight\" to your beliefs. Intuitively, think of it like what your experience (not only the personal, but everything you've seen, read etc) tells you that you should believe. For example, if you lived in Nigeria in the 1000's and you have never seen a white person, should you think that it's impossible to have a white skin? If you never heard about white people, you probably should. However, for example, if one of your friends shows you a picture of him with a white person, you probably shouldn't. Even if you are wrong a posteriori in the first case, you had more reasons to think that only black skin existed. From this perspective, you were right.</p> <p>This might sound like a reasonable way to think. However, that is far from what we tend to do. The biggest mistake we make is to forget what we don't know. And since it's impossible to know what we don't know, we have to be rigorous and always aware that we may be missing out on important information.</p>"},{"location":"blog/its-not-even-correlation/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/","title":"Lessons after one year of data science freelancing","text":"Estimated read time: 3 min"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#intro","title":"Intro","text":"<p>About a year ago, I did my last internship and officially finished my master in applied maths. I had a bit of money on the side and Yan Holtz asked me if I wanted to create an online course on matplotlib with him. My 2 options were:</p> <ul> <li>apply for jobs (I did a few interviews)</li> <li>start freelancing, create the course with Yan and look for clients</li> </ul> <p>Since I feel like I had nothing to lose, I decided to go freelance and look for a regular job if I don't have money anymore. I'll start by describing the upsides (money, workload, etc) of this decision, and then the downsides.</p> <p>I knew I'd be able to make a minimum amount of money which would have let me around a few months combined with my savings. My idea was to work on side projects / open source if I didn't have any client to work for.</p> <p>It turns out to be the best experience I could have imagined.</p> <p>Yan and I created this course (where I learned a lot about building and selling a product). We're still working on it, but most of the work is now done, students are happy and I now have a \"passive\" income (not 100%, but I don't believe such things really exist).</p> <p>At the same time, I met David Keyes via a post on LinkedIn saying he was looking for someone to write blog posts about dataviz. I've been working for him since then (almost a year now!), on many projects, as a consultant. I learn(ed) a lot, met other freelancers working for him and plan to continue to grow with him and his new company Clarity Data Studio.</p> <p>And then other people I met along the way or just contacted me offered me to work with them, which I am very grateful for.</p>"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#upsides","title":"Upsides","text":""},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#money","title":"Money","text":"<p>Since that's the thing most people (including myself) are the most interested in, I want to share exact figures.</p> <p></p> <p>To get in USD, as of the day I'm writing this, you need to multiply 1.16.</p> <p>To be honest, I earned significantly more money than I was expecting.</p> <p>At the same time, you can see that there is no pattern. Even I realized I'm pretty bad at estimating how much I'll earn next month. Also, the first 2 months were not enough for me to cover my spending. If I didn't have savings, I couldn't have started this project.</p>"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#remote","title":"Remote","text":"<p>At the moment, I've only worked 100% remotely and asynchronously. That means I work whenever I want and wherever I want, which is an amazing thing.</p> <p>One of the great things here is that it works because I work with people that trust me. My clients don't care about what I do during my day while I'm doing the job. I believe it makes me enjoy and care more about the work I'm doing because I feel responsible.</p> <p>I also have very few calls (~between 1 and 3 per week). They last around 20-30 minutes on average.</p>"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#workload","title":"Workload","text":"<p>It's very hard for me to estimate how much I work on average. And since I spend a significant amount of time doing open source work (e.g., not for clients), I need to take that into account.</p> <p>I do believe that if I only take freelance work into account, I could easily fit everything into a 9 to 4 (6 hours per day), Monday to Friday, with many weeks off over the year. If I include open source work, I think it would be more a 9 to 6, Monday to Sunday.</p> <p>That means it's perfectly possible (in my case) to have a chill work life.</p> <p>Finally, it's just great to be able to randomly just not work on a Tuesday afternoon because your unemployed friend wants to go to a caf\u00e9.</p>"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#actual-work","title":"Actual work","text":"<p>Last but not least, I love what I do. I literally learn things every day, I work with people who have a lot more experience than me and I can really benefit from that.</p> <p>I've started using tools I would have never expected to even hear about, and it makes me feel like I can just learn anything I want, assuming I take the time. My job is really about learning how to use stuff and combine them with other stuff I already know.</p> <p>I'm also super happy to be able to work on open source work, mostly on my own tools. But I'm planning to according more time to existing projects.</p>"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#downsides","title":"Downsides","text":"<p>To be honest, I don't feel like there are major downsides. The reasons for that are, I believe, very subjective. Many people might not feel the same about working remotely, not having financial visibility, etc. I still made a list because it's worth mentioning, but in my case, I'm overall very satisfied.</p> <ul> <li>If I don't have clients anymore, I don't have unemployment benefit contrary to most people where I live.</li> <li>It can be stressful to be responsible for making your clients happy. I don't stress much about it anymore.</li> <li>Sometimes I can have a very high amount of work and it's hard to predict when.</li> <li>Working fully remotely makes you solo most of the time (but that's easily solvable by working from caf\u00e9s or coworking places).</li> </ul>"},{"location":"blog/lessons-after-one-year-of-data-science-freelancing/#takeaways","title":"Takeaways","text":"<ul> <li>Luck is very useful. I'm 100% sure I had more luck than the average person. If I started over, I wouldn't expect the same results.</li> <li>Confidence matters a lot. Being able to price your work confidently, tell your client(s) that you know how to fix a given issue, and so on, gives the feeling that people can trust you.</li> <li>A very common thing, but people don't care that much about technical stuff (even other developers!) but rather about the outcome.</li> <li>Work conditions are super important. I prefer earning much less but not having to go to work every morning at 9 a.m. with people I don't particularly like.</li> <li>A single person can have a massive impact on your life, and you can't predict it. Yan and David (among others) mentioned before are just two examples that changed the picture significantly in my case, and my encounters with them were quite random.</li> <li>Life is great.</li> </ul>"},{"location":"blog/open-source-starts-with-a-good-issue/","title":"Open source starts with a good issue","text":"Estimated read time: 4 min"},{"location":"blog/open-source-starts-with-a-good-issue/#open-source-is-hard","title":"Open source is hard","text":"<p>Contributing to open source is often advised to people who want to become better software developers, and even though that's probably true, it's important to understand how contributing to open source works first.</p> <p>Often, open source projects have a large, complex codebase and potentially a large userbase. A large userbase means you can't just change the behavior of something. Renaming an argument can literally break lots of people's code.</p> <p>If it's necessary, for any reason, to change the behavior of something, then it usually takes multiple releases, starting with a deprecation warning before actually applying the breaking change. This means maintainers spend a lot of time ensuring new code doesn't break anything. This is also why open source projects have large test suites.</p> <p>Other aspects such as security, API design, or documentation become extra important as the userbase grows. These things make open source particularly demanding.</p> <p>Before making your first contribution, make sure you understand that open source requires you to fully understand what you're doing (for example, see the Automated Contributions Policy of scikit-learn).</p>"},{"location":"blog/open-source-starts-with-a-good-issue/#good-issues-are-contributions-too","title":"(Good) issues are contributions too","text":"<p>Unless you only care about being in the contributor list (which might not be the best start), code is just one way of contributing.</p> <p>People who develop open source software are not writing code all the time. A big part of the work is reviewing issues, reviewing other people's code, deciding on new features, trying to reproduce bugs, etc.</p> <p>If your goal is to help the development of an open source tool, you can be very useful by reporting bugs, especially if they are well identified.</p> <p>It's very common for people to report what they think is a bug. But if it's not reproducible, people can't help you. It helps maintainers a lot if the issue you're describing appears in a very minimal code snippet.</p> <p>We call this a reprex (Reproducible Example).</p> <p>If you're like me and you enjoy reading GitHub issues, you'll notice that so many open issues are stuck in a vague state where there seems to be a bug, but it's not obvious whether it actually is one.</p> <p>Also note that well-described and reproducible issues probably have a large impact on whether maintainers will try to fix the issue soon or not.</p> <p> </p>"},{"location":"blog/open-source-starts-with-a-good-issue/#optional-interlude-with-a-concrete-example","title":"(Optional) Interlude with a concrete example","text":"<p>Skip the example</p> <p>Recently I had an issue where a chart title had the wrong size even though I set it correctly. Here was my function with the issue:</p> <pre><code>def hbarplot(*, df: pl.DataFrame, colname: str) -&gt; None:\n   fig, ax = plt.subplots(figsize=(10, 6), dpi=300)\n   df_agg: pl.DataFrame = (\n      df.group_by(colname)\n      .len()\n      .sort(colname)\n      .with_columns(pl.col(colname).replace_strict(CODE_TO_LABEL).cast(pl.String))\n   )\n   y: list = df_agg[colname].to_list()\n   x: list = df_agg[\"len\"].to_list()\n   n: int | float = df_agg[\"len\"].sum()\n   max: int | float = df_agg[\"len\"].max()\n   font: FontProperties = load_google_font(FAMILY, weight=\"bold\")\n\n   ax.barh(y=y, width=x)\n   ax.set_title(QID_TO_QUESTION[colname], color=\"black\", font=font, size=18)\n\n   for i, val in enumerate(x):\n      ax.text(\n            x=val + max * 0.02,\n            y=i,\n            s=f\"n = {val} ({val / n * 100:.0f}%)\",\n            size=14,\n            va=\"center\",\n      )\n\n   plt.tight_layout()\n   plt.savefig(f\"src/document/plots/{colname}.png\", dpi=300, bbox_inches=\"tight\")\n   plt.close()\n</code></pre> <p>For some reason, the chart title (added via <code>set_title()</code>) kept its default size (<code>size=10</code>).</p> <p>What happens if I send this code to a maintainer with the message \"The title is too small\"? It might take them half an hour to figure out the issue and reproduce it themselves\u2014and they probably won't do it right away because it's not very fun. Instead, I spent that half hour myself trying to make the smallest possible code snippet that still shows the issue.</p> <p>Then I was able to do this:</p> <pre><code>import matplotlib.pyplot as plt\nfrom matplotlib.font_manager import FontProperties\n\nfig, ax = plt.subplots()\nax.set_title(\"hey\", size=30, font=FontProperties(family=\"Roboto\"))\n</code></pre> <p>More importantly, while writing the reprex, I realized that the issue only occurs if <code>font</code> is a <code>FontProperties()</code> object (which I was using), but not if it's a string (also accepted), such as <code>\"Roboto\"</code>.</p> <p>The result? I got an answer an hour later saying, \"This might be the same issue as this other one.\" I checked it, confirmed it was the same (but I didn't see it before), closed the issue, and got a workaround for my use case.</p> <p>Now imagine how much time it'll take if I send my original function and just vaguely describe the issue?</p> <p>If you're curious, you can find the issue here.</p> <p> </p>"},{"location":"blog/open-source-starts-with-a-good-issue/#learn-how-to-write-reprexes","title":"Learn how to write reprexes","text":"<p>A reprex is the smallest self-contained example that reliably reproduces a software issue. It should contain everything (including imports, data if necessary, etc.).</p> <p>It also shows that you've taken the first step in debugging yourself.</p> <p>Learning to write a reprex is a genuinely valuable skill. It teaches you to isolate behaviors, think carefully about what actually triggers a problem, and forces you to fully understand what's going on. It sounds simple but often requires patience and precision. Mastering it will make you a better reporter and a better developer, too.</p> <p>On a related note, I worry that LLMs make us much worse at this, but I might be wrong.</p>"},{"location":"blog/open-source-starts-with-a-good-issue/#find-your-next-contribution","title":"Find your next contribution!","text":"<p>If you're looking to make your first open source contributions, try to consider the following before doing anything:</p> <ul> <li>focus on things you use often</li> <li>focus on things you understand</li> <li>focus on things you find fun</li> <li>don't believe AI will do the hard part for you</li> <li>express yourself well, in English (LLMs can help a lot with this)</li> <li>be kind to others</li> </ul> <p>It's completely fine to be motivated by being an \"open source contributor\" (I personally am), but it's important to consider open source contributions across the entire pipeline (from discovering a bug to implementing new features).</p> <p>Once you're comfortable with this, start your first PR and enjoy the journey!</p>"},{"location":"blog/open-source-starts-with-a-good-issue/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"},{"location":"blog/statistics-in-our-daily-life/","title":"Statistics in our daily life","text":"Estimated read time: 10 min"},{"location":"blog/statistics-in-our-daily-life/#tldr","title":"TLDR","text":"<p>The aim of this article is to put on scene different ways to use the statistics \"philosophy\" or method in our life, as well as make clearer the way statistics works. Because stats might seem reserved only for some people, I want to give you the taste of how it feels to think like a statistician and give you reasons to do the same. You will see that you don't need any math or pre-requisite for this and that it might be more relevant than you think.</p>"},{"location":"blog/statistics-in-our-daily-life/#estimation","title":"Estimation","text":"<p>It is very common in statistics to want to \"estimate\" things. These can be the average body mass index of undergraduates, as well as more complex examples such as the vector of coefficients that best fits a regression between several variables. An important part of what an estimator is is the fact that we will never know its \"true\" value. The more information we have (quantity and quality), the more accurate our estimate will be, but it will never be sufficient.</p> <p>Let's say we are interested in the average number of hours a student works before an exam. One way to estimate this is to ask different students during the course and calculate the average. Since it is impossible to survey every student in the world, how do we know if the value we will get is relevant to our goal? We consider an estimator to be good when it respects certain properties.</p>"},{"location":"blog/statistics-in-our-daily-life/#is-our-estimaton-biased","title":"Is our estimaton biased?","text":"<p>A bias is simply a deviation from the original objective. Whether in statistics or in \"real life\", it has the same meaning. One can think of cognitive biases, statistical biases or more generally scientific biases. An estimator can be considered as unbiased if the difference between the expected value of the parameter studied (i.e. what we are supposed to obtain if we can interview an infinite number of students) and the \"real\" (or \"true\") parameter is zero. But one could say that if we already knew the \"true\" value of the parameter, why bother making an estimate? In fact, we don't know it and that's the problem: it is not so easy to know if our estimator is biased or not.</p> <p>Fortunately, we have mathematical statistics that can determine whether an estimator is biased or not, but they are not sufficient because they regularly assume assumptions that are not always verified (we won't talk about this in more detail here because it is mostly about mathematics and the way we collect our data).</p> <p>If we return to our example with the average number of hours students work before an exam, it's easy to find biases. For example, asking only students during class implies that students who do not attend class will not answer our question. And it seems plausible that students who don't go to class work less (or more? who knows) for exams. And if we take a completely opposite example like \"How many beers did I drink last year per week on average?\", I have to think about things like \"Does my current consumption influence what I think I drank last year?\". At this point, you might start to wonder why being so methodical about such unimportant questions. You'll find an answer to that question at the end of this article and you might be surprised.</p>"},{"location":"blog/statistics-in-our-daily-life/#does-our-estimaton-have-high-variance","title":"Does our estimaton have high variance?","text":"<p>The variance is simply a measure of dispersion. It tells us how far people in our sample tend to deviate from the mean. In contrast, a variance of zero is equivalent to everyone having the same value (i.e. in our example, all students work the same amount of time before an exam). The connection to estimation is the fact that we want to know if our estimator has a high or low variance.</p> <p>This is important because a low variance implies that, especially if our estimator is unbiased, we can be sure that we can make generalizations from our sample to the rest of the world. For example, if we estimate that a student works an average of 4 hours before an exam and we know that this estimate is unbiased and has a low variance, it is very likely that the \"true\" value is around 4.</p> <p>It is important to keep in mind that we make estimates all the time. When you wonder if you're going to find a place to park your car, which college is best for you, or if you've eaten too much, you're making an estimate. You're trying to figure something out, but because you don't have all the information in the world, you're making an approximation based on what you know.</p> <p>To that end, I think the best way to make a better estimate is to think about the possible biases and the level of variance in your estimate. In this way, it will naturally force you to doubt your beliefs and describe the problem at hand more formally.</p>"},{"location":"blog/statistics-in-our-daily-life/#inferences","title":"Inferences","text":"<p>The purpose of estimation is to make inferences. As we said before, you don't have all the information in the world. If this were not the case, estimation would be meaningless. You only have access to a (very small) sample of information, and we can define some criteria that tell us whether, based on our data, we can make generalizations to the rest of the world from that sample. In statistics, a very common way to do this is to calculate the p-value.</p> <p>For example, if we want to know if a drug is effective in reducing LDL blood cholesterol, we give it to people with high LDL and after a week compare the difference with people who also have high LDL but did not take the drug (preferably a placebo). From there, assuming the drug is not effective, we can calculate what the probability is of getting the results we did (e.g., people who took the drug reduced their LDL by 10 points and those who took the placebo by only 4 points). If this probability is very low, we can deduce that our initial hypothesis might not be true (i.e. that the drug is effective for reducing LDL blood cholesterol!).</p> <p>The convention is 5%. If a difference of 6 (10 - 4 = 6) had a probability of less than 5% of occurring, we say that our result is significant and that we cannot accept the hypothesis that the drug is ineffective.</p> <p>This concept of p-value implies other important concepts. If we take the convention of 5%, this amounts to taking a 5% risk threshold to conclude that there is an effect even if this is not the case in practice. In a slightly more formal way, we can describe:</p> <ul> <li>False positive: conclude that there is an effect even if there is not.</li> <li>False negative: conclude that there is no effect even if there is one.</li> </ul> <p>You can familiarize yourself with these concepts by thinking about a COVID-19 test. There is a probability that it will say you have it even if you don't, as well as a probability that it will say you don't have it even if you do (a bit more problematic). In practice, there is a trade-off between maximizing and minimizing the probability of false positives or negatives. In the clinical field, one would naturally prefer to minimize the probability of telling a person that there is nothing wrong with them when they are sick. This statistical concept is very important in the medical sciences.</p>"},{"location":"blog/statistics-in-our-daily-life/#more-details","title":"More details","text":"<p>There is a lot of criticism of the P-value and many people (even those who regularly do statistics) don't really understand what it means. In fact, the people who criticize the P-value are mostly criticizing the way people tend to use and interpret it. For us, it doesn't really matter because I just want to give you the conceptual idea of what a p-value is: a way to define whether what we observe is sufficiently unlikely and we have to say \"something is happening\" (in the latter case: the drug is not ineffective).</p>"},{"location":"blog/statistics-in-our-daily-life/#bayesianism","title":"Bayesianism","text":"<p>Bayesianism is an approach that assumes that beliefs can be formulated as probabilities (of distribution). For each subject in life, we can subjectively associate a probability distribution of what is true, and update this distribution with new information. Let's take an example: I believe that it rains almost every Sunday in Bordeaux. I have this belief because since I moved to Bordeaux, it rains almost every Sunday. But last year, for some reason, every other Sunday was very sunny. Adding this information to my last belief (and if I am a rational Bayesian person), I would have to change my belief. My new belief about Sunday weather in Bordeaux is more nuanced than my old belief. If I believed that 95% of Sundays are rainy and last year I only observed 50%, I need to update my belief and it will be about 70% (or any other value between 50 and 95, depending on other parameters).</p> <p>Bayesian statistics work the same way. This drug has been shown in the past to reduce blood sugar by 3 units, but in the last 3 published RCTs (clinical trials), the average effect was 2. We should start thinking that the average effect of this drug might be about 2.6 (for example). And you can use this approach for literally anything related to knowledge (i.e. a lot of things). Non-exhaustive list of questions for which it is relevant to think like a Bayesian:</p> <p>This professor was absent one out of three times last year, but only one out of ten times last semester. Every time I run, my leg hurts. But since my surgery, it only happens when I have a bad night. I think vegetarianism is bad for your health, but a study published in Nature tends to show that vegetarians have no deficiencies and are not less healthy.</p> <p>Whenever you have new information, add it to what you already know in order to update your beliefs and always improve.</p> <p>You may think this is a way of thinking that you already do sometimes, and it's probably true: it's pretty intuitive to change what we believe based on new information. But I suggest that you use this approach most of the time. Mainly, it will force you to be open-minded: unless you consider that you already know everything, new information is always better. You just have to give low \"weight\" to information that you consider poor. In fact, information from a top-notch peer-reviewed scientific paper is much better than a random Facebook user's comment on the same topic: you can't give it the same credit. You will have the opportunity to change what you think all your life and never have a closed opinion, but also to constantly remind yourself that there is a lot you don't know.</p> <p>For all these reasons, I strongly encourage you to think this way.</p>"},{"location":"blog/statistics-in-our-daily-life/#machine-learning","title":"Machine learning","text":"<p>Machine learning is a very popular field whose goal is to use optimization algorithms to create mathematical models capable of \"predicting\" things. Recommendation systems, chatGPT or tumor recognition from MRI scans are entirely based on advanced machine learning algorithms. I don't think they can be considered as pure statistical tools, because it is quite difficult to interpret what they \"learn\" from the world: they are excellent at predicting, but not so much at explaining. But as I probably said, the purpose of statistics is to give us information that we cannot perceive with raw data. However, there are still many useful concepts for what we are talking about here.</p> <p>Let's say I want to create a model that can predict if a person has a tumor using an MRI scan. To do this, I've created a dumb model that can't do anything right. When I show it a scan and ask it if there is a tumor, its answers are purely random. Then I show it a lot of MRI scans with and without tumors and tell him for each one if there is one or not. By doing this (and using optimization algorithms), it starts to learn the difference between good and bad MRI scans. Now my model is much better than it was at the beginning and I ask if there is a tumor on the new scans that it hasn't already seen. If I did all the last things right, my model can now predict if a person has a tumor using MRIs. It has \"learned\" from the example and is now able to generalize to new scans.</p> <p>If you understood that last point, you now have in mind the main idea of how machine learning works. Of course, it is much more complex in practice, but we use exactly the same logic when we train a model to perform a task.</p>"},{"location":"blog/statistics-in-our-daily-life/#overunder-fitting","title":"Over/under-fitting","text":"<p>Overfitting and under-fitting are two very important concepts in machine learning. Over-fitting occurs when we train our model, it learns so much from the example you gave it that it cannot generalize to new examples. This can happen when we over-train a model, for example. An analogy would be a student who memorizes all their lectures, but doesn't know how to respond when the professor asks a question that is based on understanding the lecture, not memorizing it (sound familiar? Yeah, me too).</p> <p>Another way to think about this concept is to consider that our experience is representative of what happens to others in life. Over the course of our lives, we have many experiences, learn from them, and then try to avoid the mistakes and repeat the positive things. This is fine until the overfitting occurs: we should not be overconfident in generalizing to new events since our experience is not necessarily representative. Also, you can see here that more experience could lead to more overfitting. One way to overcome this is to \"train\" yourself with a \"variety of data\": get into the habit of asking other people what they think about things you have experienced and compare the differences.</p> <p>On the other hand, under-fitting is when a student has not studied enough for an exam and simply cannot answer the questions. For example, it's like having no experience in public speaking and trying to give advice to others. You don't need to know everything, and being \"sub-competent\" in a given area is not a problem at all. It's actually an excellent quality to know when we don't know (probably more often than we'd like).</p>"},{"location":"blog/statistics-in-our-daily-life/#closing-remarks","title":"Closing remarks","text":"<p>This might be a good time to explain why being so methodical, even for unimportant matters, is so important. The main reason is that it creates excellent habits of epistemology. You will be more open-minded, better at describing problems formally, more critical of yourself, and learn from others. I really believe that most of our beliefs come from the way we approach information based on our epistemological habits, i.e. on a day-to-day basis.</p> <p>Another benefit of using all of these concepts on a daily basis is the fact that it makes the discussion much more precise, fun, interesting and with a great vocabulary. You can't imagine how nice it is to have a discussion with someone who always uses the right term and how easy it is to understand the point.</p> <p>This article was just an introduction to many different concepts that would all deserve a full book. I made a lot of approximations because my main goal is not to be accurate but to give you the intuition of how statistical methods work. If you don't come from a stats background, I hope you have a better understanding of stats and have found some useful concepts here for you. If you do statistics regularly, I hope you'll start thinking about using these concepts outside of work. If you are somewhere in between, I hope you learned something.</p>"},{"location":"blog/statistics-in-our-daily-life/#feedback","title":"Feedback","text":"<p>Having a different opinion? A nuance to bring? A question to ask? Please share it!</p> <p>I'm always looking for feedback. The best way to share your thoughts is to open an issue on the GitHub repository of the site.</p>"}]}